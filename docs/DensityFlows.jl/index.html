<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Overview · DensityFlows.jl</title><meta name="title" content="Overview · DensityFlows.jl"/><meta property="og:title" content="Overview · DensityFlows.jl"/><meta property="twitter:title" content="Overview · DensityFlows.jl"/><meta name="description" content="Documentation for DensityFlows.jl."/><meta property="og:description" content="Documentation for DensityFlows.jl."/><meta property="twitter:description" content="Documentation for DensityFlows.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>DensityFlows.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Overview</a><ul class="internal"><li><a class="tocitem" href="#Basics-of-normalizing-flows"><span>Basics of normalizing flows</span></a></li><li><a class="tocitem" href="#Loss-function"><span>Loss function</span></a></li><li><a class="tocitem" href="#From-here-and-beyond"><span>From here and beyond</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="manual/">Manual</a></li><li><a class="tocitem" href="example/">Example</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Public API</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="api_overview/">Overview</a></li><li><a class="tocitem" href="api_coupling/">Couplings</a></li><li><a class="tocitem" href="api_data/">Data</a></li><li><a class="tocitem" href="api_flow/">Flow</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Overview</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gaetanfacchinetti/DensityFlows.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gaetanfacchinetti/DensityFlows.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h1><p>DensityFlows.jl is a lightweight Julia package for data scientists and physicists who want a simple way to model low-dimensional probability distributions using normalizing flows. It’s built for clarity and ease of use — ideal for anyone who wants to experiment, learn, or prototype quickly without the overhead of large ML frameworks. While other libraries focus on complex, high-dimensional tasks like image generation, DensityFlows.jl keeps things minimal and transparent, helping you understand and apply normalizing flows right away.</p><h2 id="Basics-of-normalizing-flows"><a class="docs-heading-anchor" href="#Basics-of-normalizing-flows">Basics of normalizing flows</a><a id="Basics-of-normalizing-flows-1"></a><a class="docs-heading-anchor-permalink" href="#Basics-of-normalizing-flows" title="Permalink"></a></h2><p>Let us say we want to emulate a conditional probability <span>$P$</span> with distribution function <span>$p(x \, |\, \theta)$</span> (equivalent to a likelihood) for <span>$x\in \mathcal{D} \subset \mathbb{R}^d, \theta \in \mathcal{E} \subset \mathbb{R}^n$</span>, with <span>$d \in \mathbb{N}_*$</span> and <span>$n \in \mathbb{N}$</span>. To that end we can start from a probability distribution function <span>$Q$</span> with distribution function <span>$q$</span> that is known and perform a change of variable from <span>$q$</span> to <span>$p$</span>. In practice, we thus want to find the diffeomorphism <span>$f_\theta$</span> that, for <span>$z \sim Q$</span> satisfies <span>$f_\theta(z) \sim P$</span>. This requirement imposes that <span>$f_\theta$</span> satisfies</p><p class="math-container">\[p(x \, |\, \theta) = q(f_\theta^{-1}(x)) \left| {\rm det} \,  J[f_\theta^{-1}](x) \right| \quad \forall (x, \theta) \in \mathcal{D} \times \mathcal{E}\]</p><p>with <span>$J[f_\theta^{-1}]$</span> the Jacobian of the inverse transformation. Moreover, using the properties of the Jacobian, this can also be written</p><p class="math-container">\[p(x \, |\, \theta) = \frac{q(f_\theta^{-1}(x))}{\left| {\rm det} \,  J[f_\theta](f^{-1}_\theta(x)) \right|} \quad \forall (x, \theta) \in \mathcal{D} \times \mathcal{E}\]</p><p>Now, let us assume that <span>$f_\theta$</span> is written as a composition of <span>$m$</span> elementary diffeomorphisms as follows</p><p class="math-container">\[f_\theta = g_{\theta, m} \circ g_{\theta, m-1} \circ \dots \circ g_{\theta, 1}.\]</p><p>These diffeomorphisms can be defined using neural networks. Then, using the chain rule, for <span>$\theta \in \mathcal{E}$</span> and <span>$z \in f_\theta^{-1}(\mathcal{D})$</span>, </p><p class="math-container">\[\begin{equation*}
\begin{split}
J[f_\theta](z) &amp; = J[g_{\theta, m} \circ g_{\theta, m-1} \circ \dots \circ  g_{\theta, 3}\circ g_{\theta, 2} \circ g_{\theta, 1}](z) \\
 &amp; = J[g_{\theta, m} \circ g_{\theta, m-1} \circ \dots \circ g_{\theta, 3} \circ g_{\theta, 2}](g_{\theta, 1} (z)) \times  J[g_{\theta, 1}](z) \\
  &amp; = J[g_{\theta, m} \circ g_{\theta, m-1} \circ \dots \circ g_{\theta, 3}](g_{\theta, 2} \circ g_{\theta, 1}(z)) \times  J[g_{\theta, 2}](g_{\theta, 1} (z)) \times  J[g_{\theta, 1}](z) \\
 &amp; = \dots \\
 &amp; = \prod_{i=1}^{m} J[g_{\theta, i}](g_{\theta, i-1} \circ \dots \circ g_{\theta, 1}(z)) \, .
\end{split}
\end{equation*}\]</p><p>Let us now apply this relationship to <span>$z = f_\theta^{-1}(x)$</span> where <span>$x\in \mathcal{D}$</span>,</p><p class="math-container">\[\begin{equation*}
\begin{split}
J[f_\theta](f^{-1}_\theta(x)) &amp; = \prod_{i=1}^{m} J[g_{\theta, i}](g_{\theta, i-1} \circ \dots \circ g_{\theta, 1} \circ g_{\theta, 1}^{-1}  \circ \dots \circ g_{\theta, m}^{-1} (x))\\
&amp; = \prod_{i=1}^{m} J[g_{\theta, i}](g_{\theta, i}^{-1}  \circ \dots \circ g_{\theta, m}^{-1} (x)) \, .
\end{split}
\end{equation*}\]</p><p>and therefore</p><p class="math-container">\[{\rm det} \,  J[f_\theta](f^{-1}_\theta(x))  = \prod_{i=1}^{m} {\rm det} \, J[g_{\theta, i}](g_{\theta, i}^{-1}  \circ \dots \circ g_{\theta, m}^{-1} (x)) \]</p><p>In other words, we have shown that the determinant of the Jacobian can be computed recursively by multiplying the Jacobian of every diffeomorphism evaluated at a point that only depends on the previous inverse diffeomorphisms. In practice for a large number of dimension the jacobian can be long to evaluate. One solution is to use transformation with triangular jacobians which can be computed much faster.</p><h2 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h2><p>The loss function associated to the determination of <span>$f_\theta$</span> is the Kullback-Leibler divergence between <span>$p$</span> and the <em>sampled</em> distribution <span>$r$</span></p><p class="math-container">\[\begin{equation*}
\begin{split}
L &amp; = \int  r(x \, | \, \theta) \ln\frac{r(x \, | \, \theta)}{p(x \, | \, \theta)} \, {\rm d} x \\
&amp; = - \mathbb{E}_r \left[\ln p(x \, | \, \theta) \, | \, \theta \right] + {\rm cst.} \\
&amp; = - \mathbb{E}_r \left[\ln q(f_\theta^{-1}(x)) - \ln \left| {\rm det} \,  J[f_\theta](f^{-1}_\theta(x)) \right| \, | \, \theta\right]\, .
\end{split}
\end{equation*}\]</p><p>For a sample of <span>$N$</span> points <span>$\{(x, \theta)_i\}_{i\in [1, N]}$</span> it can be estimated as</p><p class="math-container">\[\begin{equation*}
\begin{split}
L &amp; \simeq \frac{1}{N} \sum_{i = 1}^N \left[\ln q(f_{\theta_i}^{-1}(x_i)) - \sum_{j=1}^m \ln \left| {\rm det} \,  J[g_{\theta_i, j}](g_{\theta_i, j}^{-1}  \circ \dots \circ g_{\theta_i, m}^{-1} (x))  \right| \right] \, .
\end{split}
\end{equation*}\]</p><h2 id="From-here-and-beyond"><a class="docs-heading-anchor" href="#From-here-and-beyond">From here and beyond</a><a id="From-here-and-beyond-1"></a><a class="docs-heading-anchor-permalink" href="#From-here-and-beyond" title="Permalink"></a></h2><p>In order to get familiar with the code please give a look at the <a href="manual/">manual</a> and at the detailed <a href="example/">example</a>. Any comment to the code or suggestion for improvement is welcome, please do so using the GitHub issues page if relevant. Further developement should include the implementation of conditional masked autoregressive flows (CMAF).</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="manual/">Manual »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 4 November 2025 15:41">Tuesday 4 November 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
